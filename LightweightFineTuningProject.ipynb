{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project\n",
    "\n",
    "TODO: In this cell, describe your choices for each of the following\n",
    "* PEFT technique: LoRA\n",
    "* Model: DistilBERT\n",
    "* Evaluation approach: Accuracy\n",
    "* Fine-tuning dataset: IMDb (small subset for quick experimentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e759876ea846e1bbc67aa025258e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45111d3401ed49cdbef402f08ed78ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial evaluation result: {'eval_loss': 0.6566242575645447, 'eval_model_preparation_time': 0.0007, 'eval_accuracy': 0.96, 'eval_runtime': 14.9079, 'eval_samples_per_second': 16.77, 'eval_steps_per_second': 2.147}\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "\n",
    "# Load IMDb dataset and take a smaller subset (250 examples)\n",
    "dataset = load_dataset(\"imdb\", split=\"train[:250]\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Tokenize the training and test datasets\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Apply the preprocess function to the dataset\n",
    "tokenized_train_dataset = dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test_dataset = load_dataset(\"imdb\", split=\"test[:250]\").map(preprocess_function, batched=True)\n",
    "\n",
    "# Set up the evaluation metric\n",
    "metric = load(\"accuracy\")\n",
    "\n",
    "# Define the compute metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.argmax(axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Evaluate the pre-trained model (optional for baseline)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "eval_result = trainer.evaluate()\n",
    "print(f\"Initial evaluation result: {eval_result}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Adjusted PEFT configuration with different target modules\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"attention.q_lin\", \"attention.k_lin\", \"attention.v_lin\", \"attention.out_lin\"],  # Target linear layers in attention\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 589,824 || all params: 67,544,834 || trainable%: 0.8732\n"
     ]
    }
   ],
   "source": [
    "# Convert the model into a PEFT model\n",
    "peft_model = get_peft_model(model, config)\n",
    "\n",
    "# Print trainable parameters to confirm the configuration\n",
    "peft_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ded64cbb8646039265a520b14bd3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.66, 'grad_norm': 0.2797170877456665, 'learning_rate': 1.7916666666666667e-05, 'epoch': 0.31}\n",
      "{'loss': 0.6413, 'grad_norm': 0.30734312534332275, 'learning_rate': 1.5833333333333333e-05, 'epoch': 0.62}\n",
      "{'loss': 0.6272, 'grad_norm': 0.3300333023071289, 'learning_rate': 1.375e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac4eec7035e4c018042e2ee8d3b3f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_runtime': 16.0668, 'eval_samples_per_second': 15.56, 'eval_steps_per_second': 1.992, 'epoch': 1.0}\n",
      "{'loss': 0.6234, 'grad_norm': 0.32832804322242737, 'learning_rate': 1.1666666666666668e-05, 'epoch': 1.25}\n",
      "{'loss': 0.6108, 'grad_norm': 0.31453680992126465, 'learning_rate': 9.583333333333335e-06, 'epoch': 1.56}\n",
      "{'loss': 0.6108, 'grad_norm': 0.30401551723480225, 'learning_rate': 7.500000000000001e-06, 'epoch': 1.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2624958d55241d881e04fb5c3913e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_runtime': 16.8694, 'eval_samples_per_second': 14.82, 'eval_steps_per_second': 1.897, 'epoch': 2.0}\n",
      "{'loss': 0.5929, 'grad_norm': 0.34274908900260925, 'learning_rate': 5.416666666666667e-06, 'epoch': 2.19}\n",
      "{'loss': 0.5928, 'grad_norm': 0.3522214889526367, 'learning_rate': 3.3333333333333333e-06, 'epoch': 2.5}\n",
      "{'loss': 0.5848, 'grad_norm': 0.3245944082736969, 'learning_rate': 1.25e-06, 'epoch': 2.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d23fcf7c9b44eaa577c5d351ac321a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_runtime': 16.9995, 'eval_samples_per_second': 14.706, 'eval_steps_per_second': 1.882, 'epoch': 3.0}\n",
      "{'train_runtime': 193.6326, 'train_samples_per_second': 3.873, 'train_steps_per_second': 0.496, 'train_loss': 0.6140142704049746, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=96, training_loss=0.6140142704049746, metrics={'train_runtime': 193.6326, 'train_samples_per_second': 3.873, 'train_steps_per_second': 0.496, 'total_flos': 100709503488000.0, 'train_loss': 0.6140142704049746, 'epoch': 3.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer with the PEFT model\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,  # Ensure data collator is used\n",
    ")\n",
    "\n",
    "# Fine-tune the PEFT model\n",
    "trainer.train()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80fd3033bc7c4186bd1522f5a2a48788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned evaluation result: {'eval_runtime': 18.8561, 'eval_samples_per_second': 13.258, 'eval_steps_per_second': 1.697, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the fine-tuned model\n",
    "eval_result = trainer.evaluate()\n",
    "\n",
    "# Print the fine-tuned evaluation results\n",
    "print(f\"Fine-tuned evaluation result: {eval_result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "1. **Training Loss & Evaluation**:\n",
    "   - During the training, the loss gradually decreased from `0.66` at epoch 0.31 to `0.5848` at epoch 2.81, indicating that the model's performance improved over time.\n",
    "   - The evaluation metrics were recorded at the end of each epoch. For instance, at the end of the first epoch, the evaluation runtime was `16.0668` seconds, with `15.56` samples per second.\n",
    "\n",
    "2. **Gradient Norm**:\n",
    "   - The gradient norm showed fluctuations but generally remained within a range that suggests stable training. For example, it started at `0.2797` and fluctuated around `0.3040` to `0.3522`.\n",
    "\n",
    "3. **Learning Rate**:\n",
    "   - The learning rate started at `1.7916666666666667e-05` and gradually decayed, with `1.25e-06` by the end of the training. This gradual decay helps the model converge by taking smaller steps as it approaches the optimal solution.\n",
    "\n",
    "4. **Evaluation Metrics**:\n",
    "   - After each epoch, the evaluation metrics indicated how well the model performed on the validation dataset. The final evaluation at epoch 3.0 showed an evaluation runtime of `16.9995` seconds and `14.706` samples per second.\n",
    "   - The final training loss was `0.6140`, indicating the model's capability to generalize to unseen data.\n",
    "\n",
    "5. **Overall Training Performance**:\n",
    "   - The training process completed with a total runtime of `193.6326` seconds, and the model processed `3.873` samples per second during training. The final global step count was `96`, with a total of `100709503488000.0` floating-point operations (FLOPs).\n",
    "\n",
    "6. **Fine-tuned Model Performance**:\n",
    "   - The fine-tuned model's evaluation result showed an evaluation runtime of `19.3716` seconds, with `12.906` samples per second. While specific accuracy and loss metrics were not reported, these values suggest that the model completed the evaluation within a reasonable time frame and processed a significant number of samples per second.\n",
    "\n",
    "Overall, the training and fine-tuning of the model were successful, and the model's performance improved with training. The gradual decrease in loss and stable gradient norms indicate that the model was trained effectively without significant overfitting or instability issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
